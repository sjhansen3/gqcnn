{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING:root:Failed to import geometry msgs in rigid_transformations.py.\n",
      "WARNING:root:Failed to import ros dependencies in rigid_transforms.py\n",
      "WARNING:root:autolab_core not installed as catkin package, RigidTransform ros methods will be unavailable\n",
      "WARNING:root:autolab_perception is not installed as a catkin package - ROS msg conversions will not be available for image wrappers\n",
      "WARNING:root:autolab_perception is not installed as a catkin package - ROS msg conversions will not be available for image wrappers\n",
      "WARNING:root:Unable to import pylibfreenect2. Python-only Kinect driver may not work properly.\n",
      "WARNING:root:Unable to import openni2 driver. Python-only Primesense driver may not work properly\n",
      "WARNING:root:Failed to import ROS in primesense_sensor.py. ROS functionality not available\n",
      "WARNING:root:primesense_sensor.py not installed as catkin package. ROS functionality not available.\n",
      "WARNING:root:Failed to import ROS in ensenso_sensor.py. ROS functionality not available\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from autolab_core import RigidTransform, YamlConfig, Point\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from generate_training_data import ProcessCornellData\n",
    "\n",
    "cfg = YamlConfig('/Users/stephenhansen/Code/gqcnn/cfg/tools/color_training.yaml')\n",
    "\n",
    "from generate_training_data import ProcessCornellData\n",
    "from gqcnn import ImageMode, TrainingMode, PreprocMode, InputDataMode, GeneralConstants, ImageFileTemplates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 64, 64, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 8, 8, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 0\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n",
      "(?, 2, 2, 512)\n"
     ]
    }
   ],
   "source": [
    "# Construct VGG model\n",
    "base_model = tf.keras.applications.VGG19(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_tensor=None,\n",
    "    input_shape=(64,64,3),\n",
    "    pooling=None,\n",
    "    classes=1000\n",
    ")\n",
    "base_model.trainable = False\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    # print layer.trainable_variables\n",
    "    # print layer.trainable_variables\n",
    "    \n",
    "# add a global spatial average pooling layer\n",
    "img = tf.placeholder(tf.float32,(None,64,64,3))\n",
    "base_out = base_model(img)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(base_out)\n",
    "# let's add a fully-connected layer\n",
    "x = tf.keras.layers.Dense(1024, kernel_initializer='glorot_normal',activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "# and binary output layer\n",
    "preds = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "#binary label outputs\n",
    "labels = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "loss = tf.reduce_mean(tf.keras.losses.binary_crossentropy(y_pred=preds, y_true=labels))\n",
    "\n",
    "# test_labels = tf.placeholder(tf.float32, shape=(None, 2,2,512))\n",
    "# test_loss = tf.reduce_mean(tf.keras.losses.mean_squared_error(y_pred=base_out, y_true=test_labels))\n",
    "# for layer in base_model.layers:\n",
    "# base_model.trainable = False\n",
    "# base_model.summary()\n",
    "# base_model.trainable = False\n",
    "# base_model.summary()\n",
    "base_model.summary()\n",
    "print base_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'block1_conv1/kernel:0' shape=(3, 3, 3, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'block1_conv1/bias:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'block1_conv2/kernel:0' shape=(3, 3, 64, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'block1_conv2/bias:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'block2_conv1/kernel:0' shape=(3, 3, 64, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'block2_conv1/bias:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'block2_conv2/kernel:0' shape=(3, 3, 128, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'block2_conv2/bias:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'block3_conv1/kernel:0' shape=(3, 3, 128, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'block3_conv1/bias:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'block3_conv2/kernel:0' shape=(3, 3, 256, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'block3_conv2/bias:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'block3_conv3/kernel:0' shape=(3, 3, 256, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'block3_conv3/bias:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'block3_conv4/kernel:0' shape=(3, 3, 256, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'block3_conv4/bias:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'block4_conv1/kernel:0' shape=(3, 3, 256, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'block4_conv1/bias:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'block4_conv2/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'block4_conv2/bias:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'block4_conv3/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'block4_conv3/bias:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'block4_conv4/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'block4_conv4/bias:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'block5_conv1/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'block5_conv1/bias:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'block5_conv2/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'block5_conv2/bias:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'block5_conv3/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'block5_conv3/bias:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'block5_conv4/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'block5_conv4/bias:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'dense/kernel:0' shape=(512, 1024) dtype=float32_ref>,\n",
       " <tf.Variable 'dense/bias:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'dense_1/kernel:0' shape=(1024, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'dense_1/bias:0' shape=(1,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup tf session and keras\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all the files which will be used for training\n",
    "data_dir = cfg['dataset_dir']\n",
    "all_filenames = os.listdir(data_dir)\n",
    "\n",
    "im_filenames = [f for f in all_filenames if f.find(ImageFileTemplates.color_im_tf_tensor_template) > -1]\n",
    "pose_filenames = [f for f in all_filenames if f.find(ImageFileTemplates.hand_poses_template) > -1]\n",
    "label_filenames = [f for f in all_filenames if f.find(cfg[\"target_metric_name\"]) > -1]\n",
    "\n",
    "# check valid filenames\n",
    "if len(im_filenames) == 0 or len(pose_filenames) == 0 or len(label_filenames) == 0:\n",
    "    raise ValueError('One or more required training files in the dataset could not be found.')\n",
    "    \n",
    "im_filenames.sort(key = lambda x: int(x[-11:-7]) if x[-11].isdigit()  else int(x[-10:-7]))\n",
    "pose_filenames.sort(key = lambda x: int(x[-11:-7]) if x[-11].isdigit()  else int(x[-10:-7]))\n",
    "label_filenames.sort(key = lambda x: int(x[-11:-7]) if x[-11].isdigit()  else int(x[-10:-7]))\n",
    "\n",
    "# subsample files\n",
    "num_files = len(im_filenames)\n",
    "num_files_used = int(cfg['total_pct'] * num_files)\n",
    "filename_indices = np.random.choice(num_files, size=num_files_used, replace=False)\n",
    "filename_indices.sort()\n",
    "im_filenames = [im_filenames[k] for k in filename_indices]\n",
    "pose_filenames = [pose_filenames[k] for k in filename_indices]\n",
    "label_filenames = [label_filenames[k] for k in filename_indices]\n",
    "\n",
    "# create copy of image, pose, and label filenames because original cannot be accessed by load and enqueue op in the case that the error_rate_in_batches method is sorting the original\n",
    "im_filenames_copy = im_filenames[:]\n",
    "pose_filenames_copy = pose_filenames[:]\n",
    "label_filenames_copy = label_filenames[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen file index uniformly at random\n",
    "def get_batch():\n",
    "    file_num = np.random.choice(len(im_filenames_copy), size=1)[0]\n",
    "    train_data_filename = im_filenames_copy[file_num]\n",
    "\n",
    "    train_data_arr = np.load(os.path.join(data_dir, train_data_filename))[\n",
    "                             'arr_0'].astype(np.float32)\n",
    "    train_poses_arr = np.load(os.path.join(data_dir, pose_filenames_copy[file_num]))[\n",
    "                              'arr_0'].astype(np.float32)\n",
    "    train_label_arr = np.load(os.path.join(data_dir, label_filenames_copy[file_num]))[\n",
    "                              'arr_0'].astype(np.float32)\n",
    "    train_label_arr = np.reshape(train_label_arr,(-1,1))\n",
    "    return train_data_arr, train_label_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 64, 64, 3)\n",
      "(10, 1)\n"
     ]
    }
   ],
   "source": [
    "[a,b] = get_batch()\n",
    "print a.shape\n",
    "print b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print train_data_filename\n",
    "# print train_label_arr.shape\n",
    "# print train_poses_arr.shape\n",
    "# print train_data_arr.shape\n",
    "# idx = 4\n",
    "# plt.imshow(train_data_arr[idx,:,:,]/255)\n",
    "# plt.title(\"train_label {} train_pose {}\".format(train_label_arr[idx], train_poses_arr[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_arr[1,:,:,]/255\n",
    "def reset_weights(model):\n",
    "    session = K.get_session()\n",
    "    for layer in model.layers: \n",
    "        if hasattr(layer, 'kernel_initializer'):\n",
    "            layer.kernel.initializer.run(session=session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable variables [<tf.Variable 'dense/kernel:0' shape=(512, 1024) dtype=float32_ref>, <tf.Variable 'dense/bias:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'dense_1/kernel:0' shape=(1024, 1) dtype=float32_ref>, <tf.Variable 'dense_1/bias:0' shape=(1,) dtype=float32_ref>]\n",
      "[[-0.0726807 ]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.0716799 ]\n",
      " [ 0.03962462]\n",
      " [-0.02923186]]\n",
      "[0.3264108]\n",
      "[[-0.07207311]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.07093821]\n",
      " [ 0.03930126]\n",
      " [-0.02923186]]\n",
      "[1.1350601]\n",
      "[[-0.07184209]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.07053073]\n",
      " [ 0.03890032]\n",
      " [-0.02923186]]\n",
      "[0.36953402]\n",
      "[[-0.0713332 ]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06998914]\n",
      " [ 0.03889877]\n",
      " [-0.02923186]]\n",
      "[0.98807466]\n",
      "[[-0.0710456 ]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06955746]\n",
      " [ 0.03871381]\n",
      " [-0.02923186]]\n",
      "[0.51205301]\n",
      "[[-0.07090059]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06918626]\n",
      " [ 0.03838534]\n",
      " [-0.02923186]]\n",
      "[0.50643504]\n",
      "[[-0.07060903]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06886208]\n",
      " [ 0.03840552]\n",
      " [-0.02923186]]\n",
      "[0.87269312]\n",
      "[[-0.07023734]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06857631]\n",
      " [ 0.03865885]\n",
      " [-0.02923186]]\n",
      "[0.71282482]\n",
      "[[-0.06986515]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06832261]\n",
      " [ 0.03908342]\n",
      " [-0.02923186]]\n",
      "[0.55461979]\n",
      "[[-0.06954036]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.0680962 ]\n",
      " [ 0.0391943 ]\n",
      " [-0.02923186]]\n",
      "[0.90911835]\n",
      "[[-0.06924929]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06789329]\n",
      " [ 0.03947344]\n",
      " [-0.02923186]]\n",
      "[0.41542637]\n",
      "[[-0.06898757]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06771085]\n",
      " [ 0.03938141]\n",
      " [-0.02923186]]\n",
      "[1.0981479]\n",
      "[[-0.06875163]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06754637]\n",
      " [ 0.03906338]\n",
      " [-0.02923186]]\n",
      "[1.0391012]\n",
      "[[-0.06853849]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06739778]\n",
      " [ 0.03858277]\n",
      " [-0.02923186]]\n",
      "[0.97631186]\n",
      "[[-0.06834559]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06726331]\n",
      " [ 0.0379929 ]\n",
      " [-0.02923186]]\n",
      "[0.86731452]\n",
      "[[-0.06817078]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06714145]\n",
      " [ 0.03756886]\n",
      " [-0.02923186]]\n",
      "[0.60604745]\n",
      "[[-0.06801217]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06703088]\n",
      " [ 0.03707139]\n",
      " [-0.02923186]]\n",
      "[0.6965518]\n",
      "[[-0.06786814]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06693047]\n",
      " [ 0.03654817]\n",
      " [-0.02923186]]\n",
      "[0.60126418]\n",
      "[[-0.06773723]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06683922]\n",
      " [ 0.03602239]\n",
      " [-0.02923186]]\n",
      "[0.50519383]\n",
      "[[-0.06761818]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06675623]\n",
      " [ 0.03552062]\n",
      " [-0.02923186]]\n",
      "[0.42465454]\n",
      "[[-0.06750987]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06668071]\n",
      " [ 0.03507831]\n",
      " [-0.02923186]]\n",
      "[1.1566741]\n",
      "[[-0.06741127]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06661198]\n",
      " [ 0.03467571]\n",
      " [-0.02923186]]\n",
      "[0.4548367]\n",
      "[[-0.0673215 ]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06654941]\n",
      " [ 0.03430913]\n",
      " [-0.02923186]]\n",
      "[1.3280115]\n",
      "[[-0.06723975]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06649241]\n",
      " [ 0.03397528]\n",
      " [-0.02923186]]\n",
      "[0.27390829]\n",
      "[[-0.06716527]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06644049]\n",
      " [ 0.03367117]\n",
      " [-0.02923186]]\n",
      "[0.29905143]\n",
      "[[-0.06709743]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.0663932 ]\n",
      " [ 0.03339413]\n",
      " [-0.02923186]]\n",
      "[1.3700813]\n",
      "[[-0.06703562]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06635011]\n",
      " [ 0.03314172]\n",
      " [-0.02923186]]\n",
      "[0.28069317]\n",
      "[[-0.0669793 ]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06631085]\n",
      " [ 0.03291175]\n",
      " [-0.02923186]]\n",
      "[1.5069225]\n",
      "[[-0.06692798]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06627508]\n",
      " [ 0.03270222]\n",
      " [-0.02923186]]\n",
      "[1.3244261]\n",
      "[[-0.06688123]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06624249]\n",
      " [ 0.03251131]\n",
      " [-0.02923186]]\n",
      "[1.2241033]\n",
      "[[-0.06683864]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.0662128 ]\n",
      " [ 0.03233737]\n",
      " [-0.02923186]]\n",
      "[0.38973936]\n",
      "[[-0.06679983]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06618575]\n",
      " [ 0.03217892]\n",
      " [-0.02923186]]\n",
      "[1.0605377]\n",
      "[[-0.06676449]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06616111]\n",
      " [ 0.03203457]\n",
      " [-0.02923186]]\n",
      "[0.45675865]\n",
      "[[-0.06673229]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06613866]\n",
      " [ 0.0319031 ]\n",
      " [-0.02923186]]\n",
      "[0.91005927]\n",
      "[[-0.06670296]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06611822]\n",
      " [ 0.03178335]\n",
      " [-0.02923186]]\n",
      "[0.83538425]\n",
      "[[-0.06667626]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.0660996 ]\n",
      " [ 0.0316743 ]\n",
      " [-0.02923186]]\n",
      "[0.73897016]\n",
      "[[-0.06665194]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06608265]\n",
      " [ 0.03157501]\n",
      " [-0.02923186]]\n",
      "[0.70430243]\n",
      "[[-0.0666298 ]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06606722]\n",
      " [ 0.03148461]\n",
      " [-0.02923186]]\n",
      "[0.74011505]\n",
      "[[-0.06660965]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06605317]\n",
      " [ 0.03140232]\n",
      " [-0.02923186]]\n",
      "[0.76430953]\n",
      "[[-0.06659131]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06604038]\n",
      " [ 0.03132742]\n",
      " [-0.02923186]]\n",
      "[0.59649253]\n",
      "[[-0.06657462]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06602874]\n",
      " [ 0.03125926]\n",
      " [-0.02923186]]\n",
      "[0.79984957]\n",
      "[[-0.06655943]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06601816]\n",
      " [ 0.03119724]\n",
      " [-0.02923186]]\n",
      "[0.80042678]\n",
      "[[-0.06654561]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06600852]\n",
      " [ 0.03114082]\n",
      " [-0.02923186]]\n",
      "[0.78014851]\n",
      "[[-0.06653304]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06599976]\n",
      " [ 0.03108949]\n",
      " [-0.02923186]]\n",
      "[0.75177157]\n",
      "[[-0.06652161]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06599179]\n",
      " [ 0.03104281]\n",
      " [-0.02923186]]\n",
      "[0.63709021]\n",
      "[[-0.06651121]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06598454]\n",
      " [ 0.03100036]\n",
      " [-0.02923186]]\n",
      "[0.71838933]\n",
      "[[-0.06650176]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06597795]\n",
      " [ 0.03096176]\n",
      " [-0.02923186]]\n",
      "[0.67596197]\n",
      "[[-0.06649317]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06597196]\n",
      " [ 0.03092667]\n",
      " [-0.02923186]]\n",
      "[0.6727342]\n",
      "[[-0.06648536]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06596652]\n",
      " [ 0.03089477]\n",
      " [-0.02923186]]\n",
      "[0.70252228]\n",
      "[[-0.06647826]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06596157]\n",
      " [ 0.03086578]\n",
      " [-0.02923186]]\n",
      "[0.67438889]\n",
      "[[-0.06647181]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06595707]\n",
      " [ 0.03083944]\n",
      " [-0.02923186]]\n",
      "[0.65583307]\n",
      "[[-0.06646594]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06595299]\n",
      " [ 0.03081551]\n",
      " [-0.02923186]]\n",
      "[0.73106086]\n",
      "[[-0.06646062]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06594928]\n",
      " [ 0.03079377]\n",
      " [-0.02923186]]\n",
      "[0.64090258]\n",
      "[[-0.06645578]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.0659459 ]\n",
      " [ 0.03077402]\n",
      " [-0.02923186]]\n",
      "[0.62749213]\n",
      "[[-0.06645139]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06594284]\n",
      " [ 0.03075608]\n",
      " [-0.02923186]]\n",
      "[0.77840298]\n",
      "[[-0.0664474 ]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06594006]\n",
      " [ 0.03073979]\n",
      " [-0.02923186]]\n",
      "[0.76114118]\n",
      "[[-0.06644378]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06593753]\n",
      " [ 0.030725  ]\n",
      " [-0.02923186]]\n",
      "[0.74862391]\n",
      "[[-0.06644049]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06593524]\n",
      " [ 0.03071157]\n",
      " [-0.02923186]]\n",
      "[0.72787029]\n",
      "[[-0.06643751]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06593316]\n",
      " [ 0.03069938]\n",
      " [-0.02923186]]\n",
      "[0.6924085]\n",
      "[[-0.06643479]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06593128]\n",
      " [ 0.03068832]\n",
      " [-0.02923186]]\n",
      "[0.65670466]\n",
      "[[-0.06643233]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06592956]\n",
      " [ 0.03067828]\n",
      " [-0.02923186]]\n",
      "[0.75015604]\n",
      "[[-0.06643011]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.065928  ]\n",
      " [ 0.03066917]\n",
      " [-0.02923186]]\n",
      "[0.76531857]\n",
      "[[-0.06642808]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.0659266 ]\n",
      " [ 0.0306609 ]\n",
      " [-0.02923186]]\n",
      "[0.77133405]\n",
      "[[-0.06642625]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06592532]\n",
      " [ 0.03065341]\n",
      " [-0.02923186]]\n",
      "[0.60273987]\n",
      "[[-0.06642458]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06592415]\n",
      " [ 0.0306466 ]\n",
      " [-0.02923186]]\n",
      "[0.58678865]\n",
      "[[-0.06642307]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.0659231 ]\n",
      " [ 0.03064043]\n",
      " [-0.02923186]]\n",
      "[0.55636084]\n",
      "[[-0.0664217 ]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06592215]\n",
      " [ 0.03063484]\n",
      " [-0.02923186]]\n",
      "[0.54387856]\n",
      "[[-0.06642045]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06592128]\n",
      " [ 0.03062976]\n",
      " [-0.02923186]]\n",
      "[0.49320117]\n",
      "[[-0.06641933]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.0659205 ]\n",
      " [ 0.03062516]\n",
      " [-0.02923186]]\n",
      "[0.47534937]\n",
      "[[-0.06641831]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06591979]\n",
      " [ 0.03062099]\n",
      " [-0.02923186]]\n",
      "[0.4296132]\n",
      "[[-0.06641738]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06591914]\n",
      " [ 0.03061721]\n",
      " [-0.02923186]]\n",
      "[0.38700661]\n",
      "[[-0.06641654]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06591855]\n",
      " [ 0.03061378]\n",
      " [-0.02923186]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.35178813]\n",
      "[[-0.06641578]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06591802]\n",
      " [ 0.03061067]\n",
      " [-0.02923186]]\n",
      "[0.33111954]\n",
      "[[-0.06641509]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06591754]\n",
      " [ 0.03060785]\n",
      " [-0.02923186]]\n",
      "[1.3191751]\n",
      "[[-0.06641446]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.0659171 ]\n",
      " [ 0.0306053 ]\n",
      " [-0.02923186]]\n",
      "[1.260528]\n",
      "[[-0.06641389]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06591671]\n",
      " [ 0.03060299]\n",
      " [-0.02923186]]\n",
      "[1.2972844]\n",
      "[[-0.06641338]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06591635]\n",
      " [ 0.03060089]\n",
      " [-0.02923186]]\n",
      "[0.3436603]\n",
      "[[-0.06641292]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06591602]\n",
      " [ 0.03059899]\n",
      " [-0.02923186]]\n",
      "[1.2841847]\n",
      "[[-0.06641249]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06591573]\n",
      " [ 0.03059727]\n",
      " [-0.02923186]]\n",
      "[1.2614205]\n",
      "[[-0.06641211]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06591547]\n",
      " [ 0.03059571]\n",
      " [-0.02923186]]\n",
      "[0.36171374]\n",
      "[[-0.06641177]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06591523]\n",
      " [ 0.0305943 ]\n",
      " [-0.02923186]]\n",
      "[0.36217651]\n",
      "[[-0.06641146]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06591501]\n",
      " [ 0.03059302]\n",
      " [-0.02923186]]\n",
      "[0.43477002]\n",
      "[[-0.06641117]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06591481]\n",
      " [ 0.03059186]\n",
      " [-0.02923186]]\n",
      "[1.1887643]\n",
      "[[-0.06641092]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06591463]\n",
      " [ 0.03059082]\n",
      " [-0.02923186]]\n",
      "[0.41188622]\n",
      "[[-0.06641069]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06591447]\n",
      " [ 0.03058987]\n",
      " [-0.02923186]]\n",
      "[1.1218743]\n",
      "[[-0.06641048]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06591432]\n",
      " [ 0.030589  ]\n",
      " [-0.02923186]]\n",
      "[0.40041456]\n",
      "[[-0.06641029]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06591418]\n",
      " [ 0.03058823]\n",
      " [-0.02923186]]\n",
      "[0.43358287]\n",
      "[[-0.06641012]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06591406]\n",
      " [ 0.03058752]\n",
      " [-0.02923186]]\n",
      "[0.41136977]\n",
      "[[-0.06640996]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06591395]\n",
      " [ 0.03058688]\n",
      " [-0.02923186]]\n",
      "[1.076051]\n",
      "[[-0.06640982]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06591386]\n",
      " [ 0.03058631]\n",
      " [-0.02923186]]\n",
      "[0.95994925]\n",
      "[[-0.06640969]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06591377]\n",
      " [ 0.03058578]\n",
      " [-0.02923186]]\n",
      "[0.49700576]\n",
      "[[-0.06640957]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06591368]\n",
      " [ 0.03058531]\n",
      " [-0.02923186]]\n",
      "[0.43452215]\n",
      "[[-0.06640947]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06591361]\n",
      " [ 0.03058488]\n",
      " [-0.02923186]]\n",
      "[1.0089201]\n",
      "[[-0.06640937]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06591354]\n",
      " [ 0.03058449]\n",
      " [-0.02923186]]\n",
      "[0.96000725]\n",
      "[[-0.06640928]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06591348]\n",
      " [ 0.03058414]\n",
      " [-0.02923186]]\n",
      "[0.59231108]\n",
      "[[-0.06640921]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06591343]\n",
      " [ 0.03058382]\n",
      " [-0.02923186]]\n",
      "[0.52774203]\n",
      "[[-0.06640914]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06591338]\n",
      " [ 0.03058354]\n",
      " [-0.02923186]]\n",
      "[0.91619319]\n",
      "[[-0.06640907]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06591333]\n",
      " [ 0.03058328]\n",
      " [-0.02923186]]\n",
      "[0.89181501]\n",
      "[[-0.06640901]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.0659133 ]\n",
      " [ 0.03058304]\n",
      " [-0.02923186]]\n",
      "[0.55826604]\n",
      "[[-0.06640896]\n",
      " [-0.0125711 ]\n",
      " [-0.02791406]\n",
      " ..., \n",
      " [-0.06591326]\n",
      " [ 0.03058283]\n",
      " [-0.02923186]]\n",
      "[0.53639156]\n"
     ]
    }
   ],
   "source": [
    "trainable_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\n",
    "                                     \"dense*\")\n",
    "print \"Trainable variables {}\".format(trainable_vars)\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss, var_list=trainable_vars)\n",
    "\n",
    "# Initialize all variables\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess.run(init_op)\n",
    "\n",
    "# Run training loop\n",
    "with sess.as_default():\n",
    "    for i in range(100):\n",
    "        batch = get_batch()\n",
    "#         print batch[0].shape\n",
    "#         print batch[0].dtype\n",
    "\n",
    "        optimizer.run(feed_dict={img: batch[0], labels: batch[1]})\n",
    "\n",
    "        print tf.trainable_variables()[-2].eval()\n",
    "        loss_out = sess.run([loss], feed_dict={img: batch[0], labels: batch[1]})\n",
    "        print loss_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'block1_conv1/kernel:0' shape=(3, 3, 3, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'block1_conv1/bias:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'block1_conv2/kernel:0' shape=(3, 3, 64, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'block1_conv2/bias:0' shape=(64,) dtype=float32_ref>,\n",
       " <tf.Variable 'block2_conv1/kernel:0' shape=(3, 3, 64, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'block2_conv1/bias:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'block2_conv2/kernel:0' shape=(3, 3, 128, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'block2_conv2/bias:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'block3_conv1/kernel:0' shape=(3, 3, 128, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'block3_conv1/bias:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'block3_conv2/kernel:0' shape=(3, 3, 256, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'block3_conv2/bias:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'block3_conv3/kernel:0' shape=(3, 3, 256, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'block3_conv3/bias:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'block3_conv4/kernel:0' shape=(3, 3, 256, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'block3_conv4/bias:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'block4_conv1/kernel:0' shape=(3, 3, 256, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'block4_conv1/bias:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'block4_conv2/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'block4_conv2/bias:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'block4_conv3/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'block4_conv3/bias:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'block4_conv4/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'block4_conv4/bias:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'block5_conv1/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'block5_conv1/bias:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'block5_conv2/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'block5_conv2/bias:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'block5_conv3/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'block5_conv3/bias:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'block5_conv4/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'block5_conv4/bias:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'dense/kernel:0' shape=(512, 1024) dtype=float32_ref>,\n",
       " <tf.Variable 'dense/bias:0' shape=(1024,) dtype=float32_ref>,\n",
       " <tf.Variable 'dense_1/kernel:0' shape=(1024, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'dense_1/bias:0' shape=(1,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GQCNN",
   "language": "python",
   "name": "gqcnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
